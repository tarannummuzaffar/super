{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarannummuzaffar/super/blob/main/Image%20classification_Assignment_3_Week_5_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfCzS_G45Xt5"
      },
      "source": [
        "**Welcome to Assignment 3 on Deep Learning for Computer Vision.**\n",
        "\n",
        "This assignment is based on the content you learned in Week-5 of course.\n",
        "\n",
        "\n",
        "#### **Instructions**\n",
        "1. Use Python 3.x to run this notebook\n",
        "2. Write your code only in between the lines 'YOUR CODE STARTS HERE' and 'YOUR CODE ENDS HERE'.\n",
        "you should not change anything else in the code cells, if you do, the answers you are supposed to get at the end of this assignment might be wrong.\n",
        "3. Read documentation of each function carefully.\n",
        "4. All the Best!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MNIST classification using CNN"
      ],
      "metadata": {
        "id": "O0eEmi9H7P4M"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Am6UM5w6DQk"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import timeit\n",
        "import unittest\n",
        "\n",
        "## Please DONOT remove these lines.\n",
        "torch.manual_seed(2024)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(2024)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RijSOxk76d6u"
      },
      "source": [
        "### Data Loading and Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kJiE9Jw1FAp"
      },
      "source": [
        "# check availability of GPU and set the device accordingly\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "device = ___\n",
        "#### YOUR CODE ENDS HERE ####\n",
        "\n",
        "# Hyper parameters\n",
        "num_epochs = 10\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# define a transforms for preparing the dataset\n",
        "# for normalization of the MNIST dataset, take mean=0.1307 and std=0.3081\n",
        "\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "transform = ___\n",
        "#### YOUR CODE ENDS HERE ####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQKIXNOr6kJY"
      },
      "source": [
        "# Load the MNIST training, test datasets using `torchvision.datasets.MNIST` using the transform defined above\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "train_dataset = ___\n",
        "test_dataset = ___\n",
        "#### YOUR CODE ENDS HERE ####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrmrFsgP6mY0"
      },
      "source": [
        "# create dataloaders for training and test datasets\n",
        "# use a batch size of 32 and set shuffle=True for the training set\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "train_dataloader = ___\n",
        "test_dataloader = ___\n",
        "#### YOUR CODE ENDS HERE ####\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvzxEVks6oKk"
      },
      "source": [
        "### Network Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHgh0YwJ6288"
      },
      "source": [
        "# Convolutional neural network (Two convolutional layers)\n",
        "class ConvolutionNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super( ConvolutionNet, self).__init__()\n",
        "\n",
        "        # define a sequential module with\n",
        "        # 1. conv layer with input channel as 1, output channels as 32, kernel size of 5, stride of 1 and padding 2\n",
        "        # 2. 2D BatchNorm of 32 features\n",
        "        # 3. ReLU activation\n",
        "        # 4. 2D MaxPool with kernel size of 2 and stride of 2\n",
        "\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "        self.conv_block1 = ___\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "        # define a sequential module with\n",
        "        # 1. conv layer with input channel as 32, output channels as 16, kernel size of 7, stride of 1 and padding 3\n",
        "        # 2. 2D BatchNorm of 16 features\n",
        "        # 3. ReLU activation\n",
        "        # 4. 2D MaxPool with kernel size of 2 and stride of 2\n",
        "\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "        self.conv_block2 =___\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "        # define a linear(dense) layer with output features corresponding to the number of classes in the dataset\n",
        "\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "        self.fc = ___\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Use the sequential convolution blocks defined above (conv_block1--> conv_block2-->fc) and\n",
        "        # write the forward pass.\n",
        "\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "        output = ___\n",
        "        output = ___\n",
        "\n",
        "        # Reshape appropiately\n",
        "        output = ___\n",
        "\n",
        "        output = ___\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDApDQj1TClB"
      },
      "source": [
        "model = ConvolutionNet(num_classes).to(device)\n",
        "model.conv_block2[0].weight.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8mfP-hKTPOX"
      },
      "source": [
        "### Question 1\n",
        "\n",
        "What is the size of parameter matrix corresponding to convolution layer of second sequential block ?\n",
        "\n",
        "1. 32x16x5x5\n",
        "2. 32x32x6x6\n",
        "3. 16x32x7x7\n",
        "4. 32x16x4x4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-DeopBwCTgd"
      },
      "source": [
        "### Training and Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyDp2L7rVSYD"
      },
      "source": [
        "#define the model\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "model = ___\n",
        "#### YOUR CODE ENDS HERE ####\n",
        "\n",
        "\n",
        "#define cross entropy loss and Adam optimizer using learning rate=learning_rate\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "# Loss and optimizer\n",
        "criterion = ___\n",
        "optimizer = ___\n",
        "#### YOUR CODE ENDS HERE ####\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_dataloader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_dataloader):\n",
        "       #### YOUR CODE STARTS HERE ####\n",
        "        # send the image, target to the device\n",
        "        images = ___\n",
        "        labels = ___\n",
        "\n",
        "        # flush out the gradients stored in optimizer\n",
        "        ___\n",
        "\n",
        "        # pass the image to the model and assign the output to variable named output\n",
        "        output = ___\n",
        "\n",
        "        # calculate the loss (use cross entropy in pytorch)\n",
        "        loss = ____\n",
        "\n",
        "        # do a backward pass\n",
        "        ____\n",
        "\n",
        "        # update the weights\n",
        "        ____\n",
        "       #### YOUR CODE ENDS HERE ####\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "# Test the model\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_dataloader:\n",
        "      ### YOUR CODE STARTS HERE ####\n",
        "        # send the image, target to the device\n",
        "        images = ___\n",
        "        labels = ___\n",
        "        # pass the image to the model and assign the output to variable named output\n",
        "        outputs = ___\n",
        "      #### YOUR CODE ENDS HERE ####\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model : {} %'.format(100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbyG43crr11p"
      },
      "source": [
        "#### Question-2\n",
        "\n",
        "Report the final test accuracy displayed above (If you are not getting the exact number shown in options, please report the closest number).\n",
        "1. 84%\n",
        "2. 76%\n",
        "3. 99%\n",
        "4. 57%\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question-3\n",
        "\n",
        "Report the loss value at the step 1800? (If you are not getting the exact number shown in options, please report the closest number).\n",
        "1. 0.0042\n",
        "2. 0.15\n",
        "3. 0.00065\n",
        "4. 1.4\n"
      ],
      "metadata": {
        "id": "PIEdZSrkSuWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Create a Function to get embeddings\n",
        "def get_embeddings(model, dataloader, device):\n",
        "    # YOUR CODE STARTS HERE\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, batch_labels in dataloader:\n",
        "            #Send images to GPU\n",
        "            images = ___\n",
        "            # Get the output of the second-to-last layer (before the final fully connected layer)\n",
        "            embedding = ___\n",
        "            # Flatten the embedding\n",
        "            embedding = ___\n",
        "            # Append the embedding and labels to the lists\n",
        "            ___\n",
        "\n",
        "    #YOUR CODE ENDS HERE\n",
        "    return np.vstack(embeddings), np.concatenate(labels)\n",
        "\n",
        "# Get embeddings for the test set\n",
        "test_embeddings, test_labels = get_embeddings(model, test_dataloader, device)\n",
        "\n",
        "# Apply t-SNE\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_results = tsne.fit_transform(test_embeddings)\n",
        "\n",
        "# Visualize the results\n",
        "plt.figure(figsize=(10, 8))\n",
        "scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=test_labels, cmap='tab10')\n",
        "plt.colorbar(scatter)\n",
        "plt.title('t-SNE visualization of MNIST test set')\n",
        "plt.xlabel('t-SNE feature 1')\n",
        "plt.ylabel('t-SNE feature 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "60w727EZcbSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question-4\n",
        "\n",
        "Embedding of which class/digit is closest to the embedding of 7?\n",
        "1. 3\n",
        "2. 5\n",
        "3. 8\n",
        "4. 1\n"
      ],
      "metadata": {
        "id": "61xMCOMpfk8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question-5\n",
        "\n",
        "Embedding of which class/digit is farthest to the embedding of 4?\n",
        "1. 1\n",
        "2. 6\n",
        "3. 9\n",
        "4. 3\n"
      ],
      "metadata": {
        "id": "jvtMz24ggok6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the weights of the first convolutional layer\n",
        "#YOUR CODE STARTS HERE\n",
        "filters = ___\n",
        "#YOUR CODE ENDS HERE\n",
        "\n",
        "print(f\"shape of the filters is: {filters.shape}\")\n",
        "\n",
        "# Normalize the filters for better visualization\n",
        "min_val = filters.min()\n",
        "max_val = filters.max()\n",
        "filters = (filters - min_val) / (max_val - min_val)\n",
        "\n",
        "# Plot the filters\n",
        "fig, axes = plt.subplots(4, 8, figsize=(12, 6))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < filters.shape[0]:\n",
        "        # Each filter is in the shape of (out_channels, in_channels, height, width)\n",
        "        # We take the first in_channel (0) since it's grayscale, so only one channel exists\n",
        "        ax.imshow(filters[i, 0, :, :], cmap='gray')\n",
        "        ax.axis('off')\n",
        "    else:\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "h9sehJ8KVhAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question-6\n",
        "\n",
        "What is the shape of filters?\n",
        "1. (32,16 , 5, 5)\n",
        "2. (32, 1, 5, 5)\n",
        "3. (16, 32, 5, 5)\n",
        "4. (16, 1)\n"
      ],
      "metadata": {
        "id": "4Bf3_mv9ot5K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2QLmeisMvHCj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}