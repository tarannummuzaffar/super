{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarannummuzaffar/super/blob/main/students_Assignment4_Week_7_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Welcome to Programming Assignment 4  on Deep Learning for Computer Vision.**\n",
        "\n",
        "\n",
        "\n",
        "#### **Instructions**\n",
        "1. Use Python 3.x to run this notebook\n",
        "2. Write your code only in between the lines 'YOUR CODE STARTS HERE' and 'YOUR CODE ENDS HERE'. You should not change anything else in the code cells. If you do, the answers you are supposed to get at the end of this assignment might be wrong.\n",
        "3. Read documentation of each function carefully.\n",
        "4. All the Best!"
      ],
      "metadata": {
        "id": "_eprGvN7N44t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow8qf6dxrGgA"
      },
      "outputs": [],
      "source": [
        "# Please DO NOT modify this cell.\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.sampler import BatchSampler\n",
        "from torch.optim import lr_scheduler\n",
        "from PIL import Image\n",
        "import timeit\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We will compute the integral image of a given gray scale image and use it to find integral of an image patch."
      ],
      "metadata": {
        "id": "cyGcRQyxzYbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('image.jpg', 0)\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "nEsmCei-cT1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h, w = img.shape  # Get the height and width of the image\n",
        "\n",
        "img_arr = np.array(img, dtype='int64')  # Convert the image to a NumPy array with integer values\n",
        "\n",
        "# Initializing the row sum and integral image arrays\n",
        "s = np.zeros((h, w))  # Array to store the cumulative row sums\n",
        "ii = np.zeros((h, w))  # Array to store the integral image\n",
        "\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "\n",
        "# Define a function to populate the row sum array `s` based on `img_arr`\n",
        "def populate_row_sum():\n",
        "    for x in range(___):  # Iterate over each row\n",
        "        s[x][0] = img_arr[___][___]  # Initialize the first element of each row\n",
        "        for y in range(___, ___):  # Iterate over each column starting from the second\n",
        "            s[x][y] = s[___][___] + img_arr[___][___]  # Update the row sum by adding the current element\n",
        "\n",
        "# Define a function to populate the integral image array `ii` based on `s`\n",
        "def populate_integral_image():\n",
        "    for y in range(___):  # Initialize the first row of the integral image\n",
        "        ii[0][y] = s[___][___]\n",
        "    for x in range(___, ___):  # Iterate over each row starting from the second\n",
        "        for y in range(___):  # Iterate over each column\n",
        "            ii[x][y] = ii[___][___] + s[___][___]  # Update the integral image by adding the row sum to the value above\n",
        "\n",
        "# Define a function to find the region sum in the image given upper left pixel coordinate (x1, y1)\n",
        "# and bottom right pixel coordinate (x2, y2) using the computed arrays `s` and `ii` with appropriate boundary conditions\n",
        "def region_sum(x1, y1, x2, y2):\n",
        "    if x2 < 0 or y2 < 0:  # Boundary condition for negative indices\n",
        "        return 0\n",
        "    d = ii[___][___]  # Value at the bottom-right corner of the region\n",
        "    a = 0\n",
        "    if x1 > 0 and y1 > 0:  # Top-left corner adjustment\n",
        "        a = ii[___][___]\n",
        "    b = 0\n",
        "    if x1 > 0:  # Top-right corner adjustment\n",
        "        b = ii[___][___]\n",
        "    c = 0\n",
        "    if y1 > 0:  # Bottom-left corner adjustment\n",
        "        c = ii[___][___]\n",
        "    return d + a - (b + c)  # Calculate the sum of the region\n",
        "#### YOUR CODE ENDS HERE ####\n"
      ],
      "metadata": {
        "id": "wDFN7D2c2W6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "populate_row_sum()\n",
        "\n",
        "populate_integral_image()\n",
        "\n",
        "print(s[90][50], ii[350][750], region_sum(100, 130, 380, 665))"
      ],
      "metadata": {
        "id": "Rk-B0JGDJb0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1:\n",
        "\n",
        "What are the respective values for the quantities s[90][50], ii[350][750], region_sum(100, 130, 380, 665) ?\n",
        "\n",
        "1.   2880, 12688949, 13923164\n",
        "2.   4880, 36188949, 25444096\n",
        "3.   5313, 37465641, 25108243\n",
        "4.   7313, 56188949, 46323164\n"
      ],
      "metadata": {
        "id": "KPRCpdPWjcsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "We will implement Multi-Task Loss for Fast R-CNN by extending the nn class of pythorch. Given the predicted logits, one-hot encoding of actual class labels, ground truth bounding box regression targets and predicted bounding box regression offsets it should return the loss value\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PVr-wObinzBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTaskLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, alpha = 0.1):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "        # Initialize a SmoothL1Loss function from the nn class of pytorch with the  reduction param as sum for Fast R-CNN\n",
        "        self.smooth_l1_loss = ____\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "    def forward(self, pred_logits, true_class, bounding_box_offsets, bounding_box_target): # refer the later code for interpretatio of the params\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "        # Calculate predicted class probabilities by taking softmax of predicted logits\n",
        "        pred = torch.softmax(pred_logits, dim=-1)\n",
        "\n",
        "        # Calculate the classification loss\n",
        "        true_class_index = ____ #index of the true class\n",
        "        L_cls = -torch.log(____)\n",
        "        # Get the bounding box regression offsets for true class\n",
        "        t_u = bounding_box_offsets[____]\n",
        "        L_loc = 0\n",
        "        # Calculate localization loss only for non background class\n",
        "        if true_class_index > 0: # give appropiate condition\n",
        "          # Calculate the localization loss(smooth L1 loss) between the true bounding box regression targets\n",
        "          # and the bounding box offsets computed above while applying the smooth_l1_loss function initialised above\n",
        "          L_loc = self.smooth_l1_loss(____, ____)\n",
        "\n",
        "        # Calculate the Multi Task loss from the two losses while using alpha as the scaling factor for the localization loss\n",
        "        Loss = L_cls + self.alpha * L_loc\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "        return Loss"
      ],
      "metadata": {
        "id": "MaoqISqkpV7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an object of MultiTaskLoss\n",
        "mt_loss=MultiTaskLoss(alpha = 0.02)"
      ],
      "metadata": {
        "id": "0lVF6l-3F13s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume predicted are the predicted logits\n",
        "predicted_logits=torch.tensor([1.4315, 2.9862, 0.4019, 1.5501])\n",
        "#One hot encoding of the true class\n",
        "true_class=torch.tensor([0., 1., 0., 0.])\n",
        "# Class wise predicted bounding box offsets\n",
        "bounding_box_offsets = torch.tensor([[25., 51., 82., 120.],[63., 42., 103., 75.],[158., 26., 94., 56.],[15., 86., 44., 80.]])\n",
        "# Bounding box regression target\n",
        "bounding_box_target = torch.tensor([58., 35., 108., 81.])"
      ],
      "metadata": {
        "id": "Xk_fkUWM89IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate multi task loss based on the above values\n",
        "#Use the MultiTaskLossMultiTaskLoss object created above\n",
        "#Print the value\n",
        "print(mt_loss(predicted_logits,true_class, bounding_box_offsets, bounding_box_target))\n"
      ],
      "metadata": {
        "id": "U3tW2GwAFmZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2:\n",
        "\n",
        "What is the value of the multi-task loss obtained above ? (Select the nearest value)\n",
        "\n",
        "1.   0.6317\n",
        "2.   0.7329\n",
        "3.   0.9435\n",
        "4.   0.8417"
      ],
      "metadata": {
        "id": "UKU4IRvwmK6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dice Loss Implementation"
      ],
      "metadata": {
        "id": "4kns7bz4OBmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def dice_loss(pred, target, smooth=1e-6):\n",
        "    \"\"\"\n",
        "    Compute the Dice loss between the predicted mask and the target mask.\n",
        "\n",
        "    Args:\n",
        "        pred (torch.Tensor): The predicted segmentation mask (batch_size x 1 x H x W).\n",
        "        target (torch.Tensor): The ground truth segmentation mask (batch_size x 1 x H x W).\n",
        "        smooth (float): A smoothing factor to avoid division by zero.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The Dice loss.\n",
        "    \"\"\"\n",
        "    # Flatten the tensors to 1D\n",
        "    pred_flat = ____\n",
        "    target_flat = ____\n",
        "\n",
        "    # Compute the intersection and union\n",
        "    intersection = ____\n",
        "    union = ____\n",
        "\n",
        "    # Compute the Dice coefficient\n",
        "    dice_coeff = ____\n",
        "\n",
        "    # Return Dice loss\n",
        "    return ____\n"
      ],
      "metadata": {
        "id": "SavFMvrk-YA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(1)\n",
        "pred_mask = torch.sigmoid(torch.randn(1, 1, 256, 256))  # Simulated prediction after sigmoid\n",
        "target_mask = torch.randint(0, 2, (1, 1, 256, 256)).float()  # Simulated binary target mask\n",
        "\n",
        "loss = dice_loss(pred_mask, target_mask)\n",
        "print(f\"Dice Loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "TL_eXNRk-d-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3:\n",
        "\n",
        "What is the value of the dice loss obtained above ? (Select the nearest value)\n",
        "\n",
        "1.   0.5018\n",
        "2.   0.6324\n",
        "3.   0.7846\n",
        "4.   0.8722\n"
      ],
      "metadata": {
        "id": "0p98npY-X-Qd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtNaqMjcX8Nn"
      },
      "source": [
        "We will be fitting an LSTM to a cosine wave."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reH70kE4XgxA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbmCW28UrGgJ"
      },
      "source": [
        "Prepare the training and testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "6Rl7DeDfrGgL"
      },
      "outputs": [],
      "source": [
        "# Please DO NOT modify this cell.\n",
        "\n",
        "def get_data():\n",
        "\n",
        "    train_x = np.arange(0, 100, 0.5)\n",
        "    train_data = np.cos(train_x)\n",
        "\n",
        "    test_x = np.arange(100, 200, 0.5)\n",
        "    test_data = np.cos(test_x)\n",
        "\n",
        "    return train_x, train_data, test_x, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "912YarlQrGgO"
      },
      "outputs": [],
      "source": [
        "# Please DO NOT modify this cell.\n",
        "\n",
        "train_x, train_data, test_x, test_data = get_data()\n",
        "\n",
        "plt.figure(figsize = (20, 4))\n",
        "plt.plot(train_x, train_data, label = 'Train')\n",
        "plt.plot(test_x, test_data, label = 'Test')\n",
        "\n",
        "plt.legend(loc = \"lower left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpTC-g2YrGgU"
      },
      "outputs": [],
      "source": [
        "# Please DO NOT modify this cell.\n",
        "\"\"\"\n",
        "Functions for creating sliding windows from the data, this is a useful function\n",
        "to understand for any time-series prediction task\n",
        "\"\"\"\n",
        "\n",
        "def sliding_windows(data, seq_length):\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkk_eNLJrGgX"
      },
      "outputs": [],
      "source": [
        "# Please DO NOT modify this cell.\n",
        "\n",
        "\"\"\"\n",
        "Create sliding windows\n",
        "\"\"\"\n",
        "\n",
        "seq_length = 5\n",
        "x_train, y_train = sliding_windows(train_data, seq_length)\n",
        "x_test, y_test = sliding_windows(test_data, seq_length)\n",
        "\n",
        "x_train = torch.Tensor(x_train)\n",
        "y_train = torch.Tensor(y_train).reshape(-1, 1)\n",
        "\n",
        "x_test = torch.Tensor(x_test)\n",
        "y_test = torch.Tensor(y_test).reshape(-1, 1)\n",
        "\n",
        "x_train = x_train[:, :, np.newaxis]\n",
        "x_test = x_test[:, :, np.newaxis]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-fbsv6_xVhu"
      },
      "source": [
        "Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC_5L1NIxUsR"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "\n",
        "        # Define a LSTM block and a FC block\n",
        "        # Set batch_first = True\n",
        "\n",
        "        self.lstm = ____\n",
        "\n",
        "        self.fc = ____\n",
        "\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "\n",
        "        # Propagate input through LSTM\n",
        "        # Pass the input, hidden state and cell_state\n",
        "\n",
        "        output, (hidden_out, cell_out) = ____\n",
        "\n",
        "        # Flatten hidden_out and pass it through fc layer\n",
        "\n",
        "        hidden_out = ____\n",
        "        out = ____\n",
        "\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQKOnThFxxuJ"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlj9F1Z6xxFR"
      },
      "outputs": [],
      "source": [
        "set_seed(2)\n",
        "num_epochs = 350\n",
        "learning_rate = 0.001\n",
        "\n",
        "input_size = 1\n",
        "hidden_size = 5\n",
        "num_layers = 1\n",
        "\n",
        "num_classes = 1\n",
        "\n",
        "# Define LSTM model\n",
        "lstm_model = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
        "\n",
        "# Set MSE loss as criterion\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "# Use Adam optimizer\n",
        "optimizer = torch.optim.Adam(lstm_model.parameters(), lr = learning_rate)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "\n",
        "    #### YOUR CODE STARTS HERE ####\n",
        "\n",
        "    # Pass x_train as input to the lstm network\n",
        "    train_predict = ____\n",
        "\n",
        "    # Clear gradients in the optimizer\n",
        "    ____\n",
        "\n",
        "    # Calculate loss using criterion function\n",
        "    loss = ____\n",
        "\n",
        "    # Calculate gradients with respect to the loss\n",
        "    ____\n",
        "\n",
        "    # Update parameters\n",
        "    ____\n",
        "\n",
        "    #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}/{num_epochs}, loss: {loss.item():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxBMnRiMapJk"
      },
      "source": [
        "## Question 4:\n",
        "\n",
        "How many parameters are there in the model?\n",
        "\n",
        "1.   117\n",
        "2.   207\n",
        "3.   166\n",
        "4.   236\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvEkSzwjrGgo"
      },
      "outputs": [],
      "source": [
        "print(sum(p.numel() for p in lstm_model.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJchxuiyrGgq"
      },
      "source": [
        "## Question 5:\n",
        "\n",
        "What is the mean squared error loss on the train set? (select the nearest value)\n",
        "\n",
        "1.   0.0058\n",
        "2.   0.1204\n",
        "3.   0.0971\n",
        "4.   0.2486\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKKHo8OXrGgs"
      },
      "outputs": [],
      "source": [
        "lstm_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred = lstm_model(x_train)\n",
        "\n",
        "train_loss = criterion(pred, y_train)\n",
        "print(f\"Train Loss: {train_loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DOKPz6irGgu"
      },
      "source": [
        "## Question 6:\n",
        "\n",
        "What is the mean squared error loss on the test set? (select the nearest value)\n",
        "\n",
        "1.   0.0218\n",
        "2.   0.0059\n",
        "3.   0.0097\n",
        "4.   0.0975\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YucaWnbcrGgv"
      },
      "outputs": [],
      "source": [
        "lstm_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred = lstm_model(x_test)\n",
        "\n",
        "test_loss = criterion(pred, y_test)\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")"
      ]
    }
  ]
}